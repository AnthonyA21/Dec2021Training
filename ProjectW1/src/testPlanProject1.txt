Automationtesting.com Test Plan

1. Introduction
		Objectives
			The primary objective of testing this application is to assure that the system meets the full requirements as 
			outlined in Online Apparels Shopping Website Business Requirements Document (BRD) V1.0, including non-functional requirements
			specified for quality and user experience purposes and performance metrics for each of those non-functional requirements.
			Furthermore, the application should satisfy all use case scenarios. More information regarding specific functionality
			objectives can be in the BRD in section 3.1.1 under Project Summary.
			
			Any changes, removals, or additions to the requirements or functional/design specification documents will be documented
			and tested to the furthest extent allowed within the project timeline and the testing team's abilities.
			
		Team Members and Responsibilities
			Developer
			Either a member of the Automationpractice organization or a contractor from the consulting firm
			chosen for staff augmentation chosen to undertake development responsibilities for the project.
			Responsible for:
				-Developing the system/application
				-Conducting Unit testing and supporting system, regression and integration testing
				-Supporting user acceptance testing
				
			Adopter
				A resource from the Automationpractice Business Development Team, chosen to undertake
				undertake formal adoption, testing, validation, and application of products or solutions 
				deployed by the development team. Responsible for:
					-Contribute to Use case, requirement development through review
					-Contribute to develop and execution of the development test scripts through review
					-Conduct Full User Acceptance, regression, and end-to-end testing; this includes 
				 	 identifying testing scenarios, building the test scripts, executing scripts and 
					 reporting test results
				
			Testing Team
				Members of the Automationpractice QA team, either in its U.S. or Europe location This group 
				is responsible for managing and conducting the entire testing process, workflow, and quality 
				management activities, excluding unit testing. Responsible for:				
					-Developing Use cases and requirements in collaboration with the Adopters
					-Producing all testing deliverables specified in section 5
					-Coordinating activities across North American and European team members

2. Scope
		2.1 In Scope
			The scope of this document is to test the following components/functionalities of the Automationpractice eCommerce site:
			-Login
			-Registration
			-Product search
			-Product listing and search results
			-Product details with available variations
			-Add to cart
			-Add to wishlist
			-Checkout and Online order payment
			-Share products on social media
			-Order placement
			-My Account
			-Order history
			-Order tracking
		
			The following non-functional requirements are also within the scope of this document:
			-The website should accomodate up to 100 users concurrently
			-Web pages should not take more than 30 seconds to load with adequate internet connection speed.
			-Web pages should not break and display page not found errors if unavailable.
			-SSL security and encryption are used for online payments.
			
			For more information regarding these non-functional requirements, please see the following 
			references in the BRD:
			NFR-001
			NFR-002
			NFR-003
			NFR-004
		
		2.2 Out of scope:
			The following components/functionalities are not considered within the scope of this document:
			-Ordering customized products
			-Real time order tracking
			-Cash On Delivery option for buyers

3. Test Methodology
	3.1 Purpose
		-This section outlines all the phases of testing to be completed before approval for product release and launch.
	
		3.1.2 Usability Testing
		-The purpose of usability testing is to ensure that the new components and features will function in a manner 
		that is acceptable to the customer. This will be conducted by members of the Business Development team on a 
		non-functional prototype created by the testing team. Testing will review the findings and provide the project 
		team with its evaluation of the impact these changes will have on the testing process and to the project as a whole.
	 
	3.1.3 Unit Testing
		-Unit Testing is conducted by the Developer during code development process to ensure that proper functionality 
		 and code coverage have been achieved by each developer both during coding and in preparation for acceptance 
		 and proceeding to regression testing.  


	3.1.4 Regression Testing
		-This includes the following types of tests: functionality, performance, stress, configuration, along with bug 
		and progress reports for each of those types. These results should be communicated by the testing team to the
		developers and other project stakeholders, along with testing and ensuring that new drops/iterations contain 
		stable fixes (regression). 

	At each iteration, a debriefing should be held.  Specifically, the report must show that to the best degree achievable
	during the iteration testing phase, all identified severity 1 and severity 2 bugs have been communicated and addressed.
	At a minimum, all severity 1 and severity 2 bugs should be resolved prior to entering the beta phase.

	3.1.5 Final release Testing
		-Testing team with end-users participates in this milestone process as well by providing confirmation feedback on new
		 issues uncovered, and input based on identical or similar issues detected earlier. The intention is to verify that 
		 the product is ready for distribution, acceptable to the customer and iron out potential operational issues. If 
		 all critical bugs are resolved by this point, testing will focus on fixing lower priority/severity bugs (severity 3)
		 and verifying application stability.
		 
	3.1.6 Testing completeness Criteria
		-Release for production can occur only after the successful completion of the application under test throughout all 
		 of the phases and milestones previously discussed above.
		 
	3.2 Test Levels
		3.2.1 Build Tests
			3.2.1.1 Level 1 - Build Acceptance Tests
				-These test cases simply ensure that the application can be built and deployed. The objective is to determine if
				 further testing is possible. If any Level 1 test case fails, the build is rejectred and sent back to development.

			3.2.1.2 Level 2 - Smoke Tests
				-These tests cases verify major Business Critical functionality a high level. Like the Build Acceptance Tests
				 above, the objective is to determine if further testing is possible. These test cases should be wide in scope,
				 but shallow in detail. All components should be touched, and every major feature should be tested briefly by the 
				 Smoke Test. If any smoke test fails, the build is rejectred and sent back to development.

			3.2.1.3 Level 2a - Bug Regression Testing
				-Every bug that was “Open” during the previous build, but marked as “Fixed, Ready for Retest” for the current
				 build under test, will need to be regressed, or re-tested.  Once the smoke test is completed, all resolved
				 bugs need to be regressed.  It should take between 5 minutes to 1 hour to regress most bugs.

		3.2.2 Milestone Tests
			3.2.2.1 Level 3 - Business Critical Functionality Tests
				-Business Critical Functionality test cases are targeted on features and functionality that the user will see and 
				 use every day. Business Critical Functionality test cases must pass by the end of every 2-3 Build Test Cycles.
				 They must be tested at least once per milestone, but do not need to be tested with every build. Therefore, the 
				 Business Critical Functionality test cases must all be executed at least once during Regression testing, and once 
				 during Final Release Testing

		3.2.3 Release Tests
			3.2.3.1 Level 4 - Standard Tests
				-Test Cases that need to be run at least once during the entire test cycle for this release. These cases are run 
				 once, not repeated as are the test cases in previous levels.These can be tested multiple times for each Milestone 
				 Test Cycle (Iteration, Final Release, etc.). 

			2.2.3.2 Level 5 - Optional Tests
				-These include edge cases for bugs that rarely occur for whatever reason, or are generally difficult to reproduce.
				 They may also include performance and scalability testing not outlined in the BRD. If time constraints allow for it, 
				 they can be executed but they are not considered a priority.
	
	3.3 Bug Regression
		-Bug Regression will be a central tenant throughout all testing phases. All bugs that are resolved as "Fixed, Ready for Retest" 
		will be regressed when Testing team is notified of the new drop containing the fixes.  When a bug passes regression it will be 
		considered "Closed, Fixed". If a bug fails regression, the testing team will notify development team by entering additional
		information into Jira. When a Severity 1 bug fails regression, the testing team should also notify development via e-mail. 
		The Test Lead will be responsible for tracking and reporting to development and product management the status of regression testing.

	3.4 Bug Triage
		-Bug Triages will be held throughout all phases of the development cycle. Bug triages will be the responsibility of the Test Lead.
		Triages will be held on a regular basis with the time frame being determined by the bug find rate and project schedules. The triage
		meetings will involve the Test Lead, Product Manager, and Development Lead. The Test Lead will provide required documentation and reports 
		on bugs for all attendees. 
		
		The purpose of the triage is to determine the type of resolution for each bug and to prioritize and determine a schedule for all 
		"Bugs To Be Fixed". These bugs will be assigned out to development team members as appropriate for rectification and report the
		resolution of each bug back in the Jira tracking system. The Test Lead will be responsible for tracking and reporting on the 
		status of all bug resolutions.		 


	3.2 Suspension Criteria and Resumption Requirements
		-Testing will be suspended on the affected software module when Smoke Test (Level 1) or Business Critical Functionality 
		 (Level 2) test case bugs are discovered after the 3rd iteration.
		-Testing will be suspended if there is critical scope change that impacts the Business Critical Functionality
		
		A bug report should be filed by Development team. After fixing the bug, Development team will follow the critical fix process 
		to provide an updated build for further testing. At that time, adopters will regress the bug, and if passes, continue testing
		the module.  

	3.3 Test Completeness
		-Testing will be considered complete when the following conditions have been met:
		2.3.1 Standard Conditions:
			-When Adopters and Developers, agree that testing is complete, the app is stable, and agree that the application meets 
			functional requirements.
			-Script execution of all test cases in all areas have passed.
			-Automated test cases have in all areas have passed.
			-All priority 1 and 2 bugs have been resolved and closed.
			-UAT team approves the test completion
			-Each test area has been signed off as completed by the Test Lead.
			-80% of all resolved severity 1 and 2 bugs have been successfully re-regressed as final validation.
			
	3.3.2 Bug Reporting & Triage Conditions:
		-Bug find rate indicates a decreasing trend prior to Zero Bug Rate (no new Sev. 1/2/3 bugs found).
		-Bug find rate remains at 0 new bugs found (Severity 1/2/3) despite a constant test effort across 3 or more days.
		-Bug severity distribution has changed to a steady decrease in Sev. 1 and 2 bugs discovered.
		-No ‘Must Fix’ bugs remaining prior despite sustained testing.
	
4. Assumptions/Risks
	4.1 Assumptions
		 -For User Acceptance testing, the Developer team has completed unit, system and integration testing and 
		  met all the Requirement’s (including quality requirements) based on Requirement Traceability Matrix.
		  User Acceptance testing will be conducted by End-users
		 -Test results will be tracked and reported daily using Jira. Script failures, along with supporting evidence, 
		  will be sesent to Developer through Jira.
		 -Use cases have been developed by Adopters with support from Testing Team for User Acceptance testing. Use 
		  cases are approved by test lead.
		 -Test scripts are developed and approved.
		 -Test Team will support and provide appropriate guidance to Adopters and Developers throughout design and development process
		 - Any major contingencies should be reported immediately after the testing kickoff meeting. 
	 
	4.2 Risks
		-Lack of employee training regarding system usage, especially involving complex functionality
		-Experience of previous similar projects and the risks that did happen and how they were handled
		-Third party products and services, such as payment processors and product suppliers
		-New versions of interfacing or component software 
		-The test team’s ability to use any new tools or technologies necessary for the test effort. 
		-Working with teams in multiple locations and some team members working remotely
		-Schedule slippage and its impact on the test schedule
		-Poor documenation for modules, components, or other deliverables
	    -Vague or volatile requirements
		-Cross platform support		
	
5.  Milestones/Deliverables
		-Test Estimates
		-Test Schedule
		-Test Plan
		-Test Scripts, Both Manual and Automated
		-Test Progress Reports
		-Bug Reports and Logs
		-Lessons Learned
	
6. Test Environment
	6.1 Tracking and Testing Tools
		-Jira
		-Selenium
		-TestNG
		
	6.2 Test Environment
		-Operating systems: Windows 10, Linux, MacOS
		-Browsers: Google Chrome 96, Mozilla Firefox 95
		-Microsoft Exchance SMTP e-mail server
	


